# Aeroclub_UAI_Team
![Team logo](https://github.com/Aleshka5/Aeroclub_UAI_Team/assets/78702396/560890b7-0ffe-47da-ad92-59952752bfb9)<br>


## Ссылки
Чтобы попасть в тестовый ноутбук нажмите сюда -> [Colaboratory](https://colab.research.google.com/drive/16pzb8iQbYPkG__h4skMc08RVlp814gfV?usp=sharing)

Чтобы ознакомиться с нашей презентацией нажмите сюда -> [Power Point](https://git.codenrock.com/aeroclub-challenge-2023/cnrprod-team-29971/email-handler/-/blob/main/UAI_Team_Aeroclub_Challenge_2023_final_25.05.pptx)
или сюда -> [Google Presentation](https://docs.google.com/presentation/d/12vJagpZxojhIfBEsMpXl6MP7mXmMpsyVnzZBRTNHPdE/edit?usp=sharing)
# PostmanAI
За последнюю неделю мы перепробовали множество гипотез, чтобы грамотно подойти к решению посталенной задачи - созданию цифрового почтальона, основанного на машинном обучении. В этом репозитории вы сможете кратко пробежать по основным составляющим этого проекта.

## Введение
Основными задачими, которые мы себе ставили для решения этого хакатона являлись:
- Поддержка двух языков 
- Скорость обработки заявок
- Возможность задавать уточняющие вопросы качественно, как человек
- Масштабируемость

## Фильтрации
Изучив данные предоставленные Aeroclub наша команда пришла к выводу, что нам необходимо их предобработать. Для это мы написали функции выполняющие следующие шаги очищения:
- **Фильтрация от слов приветствия и дргих вежливых оборотов.** (так как они не несут полезной нагрузки)
- **Флитрация от слов заглушек по типу :'NAME','EMAIL'.** (так как их не будет в реальной ситуации и это может повлечь за собой проблемы с точностью)
- **Фильтрация от тянущихся переписок.** (В процессе анализа датасета мы заметили, что некоторые сообщения тянут за собой большой ворох пересылаемых писем. Так как задача стоит в анализе нового письма, то подразумевается что каждое письмо из переписки было обработано системой ранее, а значит в дальнейшей обработке не нуждается)

## Поддержка двух языков
**Мы реализовали два языка, русский и английский, так как очень важно уметь получать письма от иностранцев**. Так, первым делом отфильтрованное сообщения попадают на анализ их языка. Всё просто если будет больше кирилицы - русское, если больше латиницы - английское.

## Скорость обработки заявок
На самом первом митаппе нам сообщили, что компания может иметь нагрузку **до 5000 писем в день**.
Так, не хитрыми вычислениями можно догадаться, что нужно обеспечить скорость **3.5 заявок в минуту** или другими словами **обрабатывать заявку за 15 секунд**.

Именно поэтому **наша система справляется с заявкой менее чем за секунду** без учёта генерации уточняющего вопроса и **за 5 секунд в полном пайплайне**.

## Масштабируемость
Плавно подходя к вопросу масштабируемости, важно отметить, что он тесно связан с пердыдущим вопросом скорости. Чем ваша система больше и сложнее, тем она менее масштабируема.

Наш PostmanAI имеет очень быстрый скелет, который справляется с большинством типовых задач. На этот скелет можно без особых усилий наложить более мощные системы по интелектуальному анализу текста и семантической сегментации, но от этого он не перестанет быстро обрабатывать простые заявки. <br>
При решении задачи нахождения сущностей мы опирались на идею о том, что нам нужно добиться ситуации, когда система либо на 100% уверена, что она сделала всё верно, либо чтобы она вернула неизвестноть (и гипотетически передала задачу более мощной системе на перепроверку). Это помогает обрабатывать только более сложные кейсы более вычислительно мощными инструментами.<br>
**Пример.**<br>
Представьте, что у вас есть функция, которая 50% заявок может верно обрабатывать за 0.1 секунды а заявку. И есть функция, которая может обрабатывать 100% заявок за 5 секунд на одну заявку. Если вы будете использвать всегда мощную функцию, то вы получите не масштабируемую медленную верно работающую функцию. Если же половину заявок будете обрабатывать первой функцией, а вторую половину более точной версией, то у вас открывается простор для масштабируемости.<br>
Так, любая часть нашей системы может стать элементом, описанным в этом примере, если просто запустить более мощные LLM модели по верх нашего скелета.

## Возможность задавать уточняющие вопросы качественно, как человек
Этим на данный момент занимается ChatGPT. Но мы иузучили большое количество других моделе LLM. И выяснили, что имея хоршее железо вы можете запустить менее мощные, но достаточные для этой задачи модели по типу:[OpenAssistant](https://huggingface.co/MetaIX/OpenAssistant-Llama-30b-4bit/tree/main)

## Наша команда
- Филенков Алексей: <a href="https://github.com/Aleshka5">Aleshka5</a><br>
- Князев Александр: <a href="https://github.com/Squderini">Squderini</a><br>
- Глебов Павел: <a href="https://github.com/Pavel-hb">Pavel-hb</a><br>
- Кузин Василий: 
- Мартынович Степан: <a href="https://github.com/Stedjey">Stedjey</a><br>
